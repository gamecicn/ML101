{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04 Gradient Descend.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNJ4C5n1lFLHLF3hgCHS/oI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 04 Gradient Descend"],"metadata":{"id":"N3Z_3uU3JPzb"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"rkuqHvGaJLL-","executionInfo":{"status":"ok","timestamp":1641519598600,"user_tz":300,"elapsed":160,"user":{"displayName":"Martin Guo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16185512784682549136"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","source":["# Manual write gredient decent\n","$f = 2 * x$"],"metadata":{"id":"CFS1YQxbJkRX"}},{"cell_type":"code","source":["X = np.array([1, 2, 3, 4], dtype=np.float32)\n","Y = np.array([2, 4, 6, 8], dtype=np.float32)\n","\n","w = 0.0\n","\n","# Traget function\n","def forward(x):\n","  return w * x\n","\n","# loss = MSE\n","def loss(y, y_predicted):\n","  return ((y_predicted-y)**2).mean()\n","\n","# gradient\n","# MES = 1/N * (w*y - y)**2\n","# dJ/dw = 1/N 2x(w*x - y)\n","\n","def gradient(x, y, y_predicted):\n","  return np.dot(2*x, y_predicted-y).mean()\n","\n","print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n","\n","# Traning\n","learning_rate = 0.01\n","n_iters = 10\n","\n","for epoch in range(n_iters):\n","  # forward\n","  y_pred = forward(X)\n","\n","  #loss\n","  l = loss(Y, y_pred)\n","\n","  dw = gradient(X, Y, y_pred)\n","\n","  #update weights\n","  w -= learning_rate * dw\n","\n","  if epoch % 1 == 0:\n","    print(f'epoch {epoch + 1}: w= {w:.3f}, loss={l:.8f}')\n","\n","\n","print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9sPK5qdVJrqr","executionInfo":{"status":"ok","timestamp":1641522478512,"user_tz":300,"elapsed":195,"user":{"displayName":"Martin Guo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16185512784682549136"}},"outputId":"d9a284bc-849b-4f61-f7e0-f6b6803d297e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction before training: f(5) = 0.000\n","epoch 1: w= 1.200, loss=30.00000000\n","epoch 2: w= 1.680, loss=4.79999924\n","epoch 3: w= 1.872, loss=0.76800019\n","epoch 4: w= 1.949, loss=0.12288000\n","epoch 5: w= 1.980, loss=0.01966083\n","epoch 6: w= 1.992, loss=0.00314574\n","epoch 7: w= 1.997, loss=0.00050331\n","epoch 8: w= 1.999, loss=0.00008053\n","epoch 9: w= 1.999, loss=0.00001288\n","epoch 10: w= 2.000, loss=0.00000206\n","Prediction after training: f(5) = 9.999\n"]}]},{"cell_type":"markdown","source":["# Do the thing with pytorch"],"metadata":{"id":"Gb-LMxs_XZwO"}},{"cell_type":"code","source":["import torch \n","\n","X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n","Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n","\n","w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n","\n","learning_rate = 0.01\n","n_iters = 30\n","\n","for epoch in range(n_iters):\n","\n","  # prediction = forward pass\n","  y_pred = forward(X)\n","\n","  # loss\n","  l = loss(Y, y_pred)\n","\n","  # calculate gredient\n","  l.backward() # dl/dw\n","\n","  with torch.no_grad():\n","    w -= learning_rate * w.grad\n","  \n","  # zero gradient\n","  w.grad.zero_()\n","\n","  if epoch % 1 == 0:\n","    print(f'epoch {epoch + 1}: w= {w:.3f}, loss={l:.8f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pRutTxOJ2Kv","executionInfo":{"status":"ok","timestamp":1641524265394,"user_tz":300,"elapsed":166,"user":{"displayName":"Martin Guo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16185512784682549136"}},"outputId":"6aaf1f61-6d78-44b9-c495-b2873787d8c4"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1: w= 0.300, loss=30.00000000\n","epoch 2: w= 0.555, loss=21.67499924\n","epoch 3: w= 0.772, loss=15.66018772\n","epoch 4: w= 0.956, loss=11.31448650\n","epoch 5: w= 1.113, loss=8.17471695\n","epoch 6: w= 1.246, loss=5.90623236\n","epoch 7: w= 1.359, loss=4.26725292\n","epoch 8: w= 1.455, loss=3.08308983\n","epoch 9: w= 1.537, loss=2.22753215\n","epoch 10: w= 1.606, loss=1.60939169\n","epoch 11: w= 1.665, loss=1.16278565\n","epoch 12: w= 1.716, loss=0.84011245\n","epoch 13: w= 1.758, loss=0.60698116\n","epoch 14: w= 1.794, loss=0.43854395\n","epoch 15: w= 1.825, loss=0.31684780\n","epoch 16: w= 1.851, loss=0.22892261\n","epoch 17: w= 1.874, loss=0.16539653\n","epoch 18: w= 1.893, loss=0.11949898\n","epoch 19: w= 1.909, loss=0.08633806\n","epoch 20: w= 1.922, loss=0.06237914\n","epoch 21: w= 1.934, loss=0.04506890\n","epoch 22: w= 1.944, loss=0.03256231\n","epoch 23: w= 1.952, loss=0.02352631\n","epoch 24: w= 1.960, loss=0.01699772\n","epoch 25: w= 1.966, loss=0.01228084\n","epoch 26: w= 1.971, loss=0.00887291\n","epoch 27: w= 1.975, loss=0.00641066\n","epoch 28: w= 1.979, loss=0.00463169\n","epoch 29: w= 1.982, loss=0.00334642\n","epoch 30: w= 1.985, loss=0.00241778\n"]}]}]}